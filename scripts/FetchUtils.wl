(* ::Package:: *)
(* :Title: FetchUtils *)
(* :Context: FetchUtils` *)
(* :Author: Auto-generated by Copilot (reformatted) *)
(* :Summary: Shared utility functions for NASA CMR queries and dataset downloads. *)
(* :Package Version: 0.1.0 *)
(* :Mathematica Version: 13.2 *)

BeginPackage["FetchUtils`"];

FetchUtils`CMRCollectionSearch::usage = "CMRCollectionSearch[queryAssoc] performs a collection-level search against NASA CMR and returns an association of results.";
FetchUtils`CMRGranuleSearch::usage      = "CMRGranuleSearch[queryAssoc] searches granules for a given short name / collection with temporal & spatial constraints.";
FetchUtils`CMRGetJSON::usage            = "CMRGetJSON[url, params] issues an HTTP GET returning parsed JSON (Association).";
FetchUtils`DownloadIfNeeded::usage      = "DownloadIfNeeded[url, dest, force:False] downloads to dest unless it already exists (unless force). Returns file path or $Failed.";
FetchUtils`NormalizeRegion::usage       = "NormalizeRegion[spec] converts a region specification into {lonMin, lonMax, latMin, latMax}.";
FetchUtils`DateRangeISO8601::usage      = "DateRangeISO8601[start,end] returns an ISO8601 interval string acceptable to CMR temporal parameter.";
FetchUtils`VerbosePrint::usage          = "VerbosePrint[flag, expr__] prints expr when flag is True.";
FetchUtils`ParseCLIArgs::usage          = "ParseCLIArgs[list] returns an association mapping flags to values (boolean flags -> True).";
FetchUtils`UsageAndQuit::usage          = "UsageAndQuit[text, code:0] writes usage text and quits with code.";
FetchUtils`BuildManifest::usage         = "BuildManifest[queryAssoc, items, downloaded] constructs a manifest association summarizing results.";
FetchUtils`WriteManifest::usage         = "WriteManifest[dir, manifest] writes manifest as JSON with timestamped filename and returns path.";
FetchUtils`DownloadArbitrary::usage     = "DownloadArbitrary[url, dir, force:False] downloads any URL into dir and returns full path or $Failed.";
FetchUtils`ParseRegionString::usage     = "ParseRegionString[str] attempts multiple strategies to parse a region '{lonMin,lonMax,latMin,latMax}'. Returns list of 4 integers if successful or $Failed.";
FetchUtils`GetEarthdataHeaders::usage = "GetEarthdataHeaders[] returns an array of header rules including Authorization if EARTHDATA_TOKEN env var or $EarthdataToken is set.";

Begin["`Private`"];

$CMRBase = "https://cmr.earthdata.nasa.gov/search";
$EarthdataToken = None; (* Set via $EarthdataToken or EARTHDATA_TOKEN env var; avoid hard-coding secrets in repo *)

(* Robust JSON parsing with multiple fallbacks; prefers RawJSON which already yields Associations *)
ParseJSONSafe[txt_String] := Module[{res = $Failed, dbg = ValueQ[$CMRDebug] && TrueQ[$CMRDebug]},
    (* 1. Try RawJSON first (fast, no post-processing) *)
    res = Quiet @ Check[ImportString[txt, "RawJSON"], $Failed];
    If[dbg, WriteString[$Output, "[cmr-debug] RawJSON head=" <> ToString[Head[res]] <> "\n"]];
    (* 2. If RawJSON gave list of rules, coerce to Association *)
    If[MatchQ[res, {__Rule}], res = Association @ res];
    (* 3. If still not association, try standard JSON importer *)
    If[! AssociationQ @ res,
        res = Quiet @ Check[ImportString[txt, "JSON"], $Failed];
        If[MatchQ[res, {__Rule}], res = Association @ res];
    ];
    (* 4. Developer`ReadRawJSON as final fallback if text looks like JSON object *)
    If[! AssociationQ @ res && StringStartsQ[StringTrim @ txt, "{"],
        res = Quiet @ Check[Developer`ReadRawJSON[txt], $Failed];
        If[MatchQ[res, {__Rule}], res = Association @ res];
    ];
    If[dbg && ! AssociationQ @ res, WriteString[$Output, "[cmr-debug] JSON parsing failed, returning $Failed\n"]];
    If[AssociationQ @ res, res, $Failed]
];

(* Download file if it doesn't exist or if force is True *)

Options[CMRGetJSON] = {"Headers" -> {}, "Retry" -> 2, "Pause" -> 1.5, "IncludeBody" -> False};
CMRGetJSON[url_, params_, OptionsPattern[]] := Module[
    {query, tries = 0, max, pause, headers, httpResp, status, body, parsed, includeBody = OptionValue["IncludeBody"], bodyString},
    query = URLBuild[url, Normal @ params];
    max = OptionValue["Retry"];
    pause = OptionValue["Pause"];
    headers = Join[GetEarthdataHeaders[], OptionValue["Headers"]];
    While[tries <= max,
        httpResp = Quiet @ URLRead[HTTPRequest[query, <|"Headers" -> headers|>]];
        If[Head[httpResp] === HTTPResponse,
            status = httpResp["StatusCode"];
            body = Quiet @ httpResp["Body"];
            bodyString = Which[
                MatchQ[body, _ByteArray], Quiet @ Check[FromCharacterCode[Normal @ body, "UTF-8"], ToString @ body],
                StringQ[body], body,
                True, ToString @ body
            ];
            parsed = ParseJSONSafe[bodyString];
            Which[
                AssociationQ @ parsed && KeyExistsQ[parsed, "errors"],
                    Return @ Association[<|"success" -> False, "status" -> status, "errors" -> parsed["errors"], "url" -> query|>, If[includeBody, <|"body" -> bodyString|>, <||>]],
                AssociationQ @ parsed && status >= 200 && status < 300,
                    Return @ Association[parsed, <|"success" -> True, "status" -> status, "url" -> query|>, If[includeBody, <|"body" -> bodyString|>, <||>]],
                True,
                    Return @ Association[<|"success" -> (200 <= status < 300), "status" -> status, "raw" -> bodyString, "url" -> query|>, If[includeBody, <|"body" -> bodyString|>, <||>]]
            ];
        ];
        tries++;
        Pause[pause];
    ];
    <|"success" -> False, "status" -> Missing["NoHTTP"], "errors" -> {"No HTTP response"}, "url" -> query|>
];

CMRGetJSON[url_String, OptionsPattern[]] := CMRGetJSON[url, <||>];
GetEarthdataHeaders[] := Module[{env = Quiet @ Check[Environment["EARTHDATA_TOKEN"], None], tok},
    tok = Which[
        StringLength @ ToString @ $EarthdataToken > 0 && StringQ @ $EarthdataToken, $EarthdataToken,
        StringQ @ env && StringLength[env] > 0, env,
        True, None
    ];
    If[tok === None, {}, {"Authorization" -> ("Bearer " <> tok)}]
];

CMRGetJSON::fail = "Failed to retrieve JSON from `1`.";

(* Collection search *)
Options[CMRCollectionSearch] = {"Keywords" -> None, "ShortName" -> None, "Provider" -> None, "Limit" -> 50, "IncludeBody" -> False, "Page" -> 1};
CMRCollectionSearch[assoc_Association, opts : OptionsPattern[]] := Module[{rawParams, params},
    rawParams = <|
        "page_size" -> OptionValue["Limit"],
        "keyword" -> Lookup[assoc, "Keyword", OptionValue["Keywords"]],
        "short_name" -> Lookup[assoc, "ShortName", OptionValue["ShortName"]],
        "provider" -> Lookup[assoc, "Provider", OptionValue["Provider"]],
        "page_num" -> OptionValue["Page"]
    |>;
    params = Association @ KeyValueMap[If[StringQ[#2] || IntegerQ[#2], #1 -> #2, Sequence @@ {}] &, rawParams];
    CMRGetJSON[$CMRBase <> "/collections.json", params, "IncludeBody" -> OptionValue["IncludeBody"]]
];

Options[CMRGranuleSearch] = {"ShortName" -> None, "Temporal" -> None, "BoundingBox" -> None, "Limit" -> 200, "IncludeBody" -> False, "CollectionConceptId" -> None, "Version" -> None, "Provider" -> None, "Page" -> 1};
CMRGranuleSearch[assoc_Association, opts : OptionsPattern[]] := Module[{params, bb, temporal, ccid, version, provider, page},
    bb = Lookup[assoc, "BoundingBox", OptionValue["BoundingBox"]];
    temporal = Lookup[assoc, "Temporal", OptionValue["Temporal"]];
    ccid = Lookup[assoc, "CollectionConceptId", OptionValue["CollectionConceptId"]];
    version = Lookup[assoc, "Version", OptionValue["Version"]];
    provider = Lookup[assoc, "Provider", OptionValue["Provider"]];
    page = OptionValue["Page"];
    params = <|
        "short_name" -> Lookup[assoc, "ShortName", OptionValue["ShortName"]],
        "temporal" -> temporal,
        "bounding_box" -> If[ListQ @ bb, StringRiffle[bb, ","], Nothing],
        "collection_concept_id" -> ccid,
        "version" -> version,
        "provider" -> provider,
        "page_size" -> OptionValue["Limit"],
        "page_num" -> page,
        "sort_key" -> "-start_date"
    |>;
    params = Association @ KeyValueMap[If[#2 === None || #2 === Null || #2 === "" || #2 === Nothing, Sequence @@ {}, #1 -> #2] &, params];
    CMRGetJSON[$CMRBase <> "/granules.json", params, "IncludeBody" -> OptionValue["IncludeBody"]]
];

NormalizeRegion[spec_] := Which[
    MatchQ[spec, {_?NumericQ, _?NumericQ, _?NumericQ, _?NumericQ}], spec,
    MatchQ[spec, {_?NumericQ, _?NumericQ}], With[{lat = spec[[1]], lon = spec[[2]], d = 1.0}, {lon - d, lon + d, lat - d, lat + d}],
    True, (Message[NormalizeRegion::bad, spec]; $Failed)
];
NormalizeRegion::bad = "Unrecognized region specification `1`.";

DateRangeISO8601[start_, end_] := Module[{s, e},
    s = DateString[start, "ISODateTime"];
    e = DateString[end, "ISODateTime"];
    s <> "/" <> e
];

DownloadIfNeeded[url_, dest_, force_ : False] := Module[{dir = DirectoryName[dest]},
    If[! DirectoryQ @ dir, CreateDirectory[dir, CreateIntermediateDirectories -> True]];
    If[FileExistsQ @ dest && ! TrueQ @ force, Return[dest]];
    Quiet @ Check[URLDownload[url, dest]; dest, $Failed]
];

(* Region parsing now includes all fallback attempts internally *)
ParseRegionString[str_String] := Module[{primary, clean, parts, nums, trySeq},
    (* Strategy 1: direct interpreter on original*)
    primary = Quiet @ Check[Interpreter[DelimitedSequence["Integer", {"{", ",", "}"}]][str], $Failed];
    If[MatchQ[primary, {__Integer}] && Length[primary] == 4, Return[primary]];
    (* Strategy 2: strip whitespace and retry *)
    clean = StringReplace[str, Whitespace -> ""];
    If[clean =!= str,
        primary = Quiet @ Check[Interpreter[DelimitedSequence["Integer", {"{", ",", "}"}]][clean], $Failed];
        If[MatchQ[primary, {__Integer}] && Length[primary] == 4, Return[primary]]
    ];
    (* Strategy 3: manual split *)
    parts = StringSplit[StringTrim[clean, "{}"], ","];
    If[Length[parts] != 4, Return[$Failed]];
    nums = Interpreter["Integer"] /@ parts;
    If[AnyTrue[nums, # === $Failed &], Return[$Failed]];
    nums
];
ParseRegionString[_] := $Failed;

VerbosePrint[flag_, expr__] := If[TrueQ @ flag, WriteString[$Output, StringRiffle[ToString /@ {expr}, " "] <> "\n"]];

ParseCLIArgs[list_List] := Module[{assoc = <||>, i = 1, n = Length[list], tok, next},
    While[i <= n,
        tok = list[[i]];
        If[StringStartsQ[tok, "-"],
            Switch[tok,
                "-h" | "--help", assoc["help"] = True;,
                "--force", assoc["force"] = True;,
                "--verbose", assoc["verbose"] = True;,
                _, With[{name = StringReplace[tok, StartOfString ~~ "-" .. -> ""]},
                    If[i < n && ! StringStartsQ[list[[i + 1]], "-"],
                        next = list[[i + 1]]; assoc[name] = next; i++;,
                        assoc[name] = True;
                    ];
                ]
            ],
            Null
        ];
        i++;
    ];
    assoc
];

UsageAndQuit[text_, code_ : 0] := (WriteString[$Output, text <> "\n"]; Throw[code, "UsageQuitTag"]);

BuildManifest[query_Association, items_List, downloaded_List] := Module[{summarize, now = DateString[Now, "ISODateTime"], withLinks},
    summarize = Function[entry,
        Module[{links = Lookup[entry, "links", {}]},
            <|
                "id" -> Lookup[entry, "id", Null],
                "title" -> Lookup[entry, "title", Null],
                "time_start" -> Lookup[entry, "time_start", Null],
                "time_end" -> Lookup[entry, "time_end", Null],
                "updated" -> Lookup[entry, "updated", Null],
                "producer_granule_id" -> Lookup[entry, "producer_granule_id", Null],
                "links" -> links,
                "hasLinks" -> (ListQ[links] && links =!= {})
            |>
        ]
    ];
    withLinks = Count[summarize /@ items, KeyValuePattern["hasLinks" -> True]];
    Module[{downloadedNorm = (If[StringQ[#] && FileExistsQ[#], <|"file" -> #, "size" -> FileByteCount[#], "md5" -> FileHash[#, "MD5"]|>, #]) & /@ downloaded},
        <|
            "schemaVersion" -> "1.1.0",
            "tool" -> "SharksFromSpaceFetcher",
            "generated" -> now,
            "query" -> query,
            "statusSummary" -> <|"total" -> Length[items], "withLinks" -> withLinks, "downloaded" -> Count[downloadedNorm, KeyValuePattern["file" -> _String]]|>,
            "downloads" -> downloadedNorm,
            "entries" -> summarize /@ items
        |>
    ]
];

DownloadArbitrary[url_String, dir_, force_ : False] := Module[{safeName, path},
    If[! DirectoryQ @ dir, CreateDirectory[dir, CreateIntermediateDirectories -> True]];
    safeName = With[{take = FileNameTake @ URLParse[url, "Path"]}, If[StringLength[take] > 0, take, StringReplace[Hash[url, "MD5"] // ToString, Except[AlphanumericCharacter] -> ""] <> ".dat"]];
    path = FileNameJoin[{dir, safeName}];
    If[FileExistsQ @ path && ! force, Return[path]];
    Quiet @ Check[URLDownload[url, path]; path, $Failed]
];

WriteManifest[dir_, manifest_Association] := Module[{path = FileNameJoin[{dir, "manifest.json"}]},
    Quiet @ Check[Export[path, manifest, "JSON"]; path, $Failed]
];

End[];
EndPackage[];
